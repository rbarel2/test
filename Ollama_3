import json
import requests

# NOTE: ollama must be running for this to work, start the ollama app or run `ollama serve`
model = 'llama3'  # TODO: update this for whatever model you wish to use

def fine_tune(model, training_data, epochs):
    r = requests.post('http://localhost:11434/api/fine-tune',
                      json={
                          'model': model,
                          'training_data': training_data,
                          'epochs': epochs,
                      })
    r.raise_for_status()
    
    response = r.json()
    if 'error' in response:
        raise Exception(response['error'])
    
    return response

def generate(prompt, context):
    r = requests.post('http://localhost:11434/api/generate',
                      json={
                          'model': model,
                          'prompt': prompt,
                          'context': context,
                      },
                      stream=True)
    r.raise_for_status()

    for line in r.iter_lines():
        body = json.loads(line)
        response_part = body.get('response', '')
        print(response_part, end='', flush=True)

        if 'error' in body:
            raise Exception(body['error'])

        if body.get('done', False):
            return body['context']

def main():
    # Hypothetical training data
    training_data = [
        {"input": "Hello, how are you?", "output": "I'm fine, thank you."},
        {"input": "What's the weather like?", "output": "It's sunny and warm."}
    ]
    epochs = 3  # Number of fine-tuning epochs

    # Step 1: Fine-tune the model
    print("Fine-tuning the model...")
    fine_tune_response = fine_tune(model, training_data, epochs)
    print("Fine-tuning completed.")

    # Step 2: Interact with the fine-tuned model
    context = []  # The context stores a conversation history, you can use this to make the model more context-aware
    while True:
        user_input = input("Enter a prompt: ")
        if not user_input:
            exit()
        print()
        context = generate(user_input, context)
        print()

if __name__ == "__main__":
    main()
